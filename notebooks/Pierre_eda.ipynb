{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel evolution analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pyarrow.feather as feather\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from utils.plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_PATH = os.getcwd()\n",
    "MAIN_PATH = os.path.dirname(NOTEBOOK_PATH)\n",
    "DATA_PATH = os.path.join(MAIN_PATH, 'data_youniverse')\n",
    "SITE_DATA_PATH = os.path.join(MAIN_PATH, 'website_data')\n",
    "PEOPLE_AND_BLOGS_PATH = os.path.join(SITE_DATA_PATH, 'People_&_Blogs')\n",
    "\n",
    "if not os.path.exists(PEOPLE_AND_BLOGS_PATH):\n",
    "    os.makedirs(PEOPLE_AND_BLOGS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Important Note**: Only run this once, later on, read the Dataframes instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feather = feather.read_feather(os.path.join(DATA_PATH, 'yt_metadata_helper.feather')) # takes around 9m\n",
    "channels = pd.read_csv(os.path.join(DATA_PATH, \"df_channels_en.tsv.gz\"), compression=\"infer\", sep=\"\\t\")\n",
    "timeseries = pd.read_csv(os.path.join(DATA_PATH, \"df_timeseries_en.tsv.gz\"), compression=\"infer\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels[\"join_date\"] = pd.to_datetime(channels[\"join_date\"])\n",
    "timeseries[\"datetime\"] = pd.to_datetime(timeseries[\"datetime\"])\n",
    "df_feather[\"upload_date\"] = pd.to_datetime(df_feather[\"upload_date\"])\n",
    "df_feather[\"year_month\"] = df_feather['upload_date'].dt.to_period('M')\n",
    "df_feather[\"like_rate\"] = df_feather[\"like_count\"] / (df_feather[\"like_count\"] + df_feather[\"dislike_count\"])\n",
    "channels_PB = channels[channels['category_cc'] == \"People & Blogs\"]\n",
    "df_feather_PB = df_feather[df_feather[\"channel_id\"].isin(channels_PB[\"channel\"])]\n",
    "timeseries_PB = timeseries[timeseries['channel'].isin(channels_PB['channel'])]\n",
    "df_feather.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save resulting channel and helper dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframes will be saved withing the /website_data/People_&_Blogs folder since they are used for the website\n",
    "df_feather_PB.reset_index().to_feather(os.path.join(PEOPLE_AND_BLOGS_PATH, \"df_PB_helper.feather\"))\n",
    "channels_PB.to_csv(os.path.join(PEOPLE_AND_BLOGS_PATH,\"df_PB_channels.csv.gz\"), compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channels_PB = pd.read_csv(os.path.join(PEOPLE_AND_BLOGS_PATH, \"df_PB_channels.csv.gz\"),  compression='infer')\n",
    "df_feather_PB = pd.read_feather(os.path.join(PEOPLE_AND_BLOGS_PATH, \"df_PB_helper.feather\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18413 entries, 0 to 18412\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   category_cc         18413 non-null  object \n",
      " 1   join_date           18413 non-null  object \n",
      " 2   channel             18413 non-null  object \n",
      " 3   name_cc             18413 non-null  object \n",
      " 4   subscribers_cc      18413 non-null  int64  \n",
      " 5   videos_cc           18413 non-null  int64  \n",
      " 6   subscriber_rank_sb  18413 non-null  float64\n",
      " 7   weights             18413 non-null  float64\n",
      "dtypes: float64(2), int64(2), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5553837 entries, 0 to 5553836\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   index          int64         \n",
      " 1   categories     object        \n",
      " 2   channel_id     object        \n",
      " 3   dislike_count  float64       \n",
      " 4   display_id     object        \n",
      " 5   duration       int64         \n",
      " 6   like_count     float64       \n",
      " 7   upload_date    datetime64[ns]\n",
      " 8   view_count     float64       \n",
      " 9   year_month     period[M]     \n",
      " 10  like_rate      float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(2), object(3), period[M](1)\n",
      "memory usage: 466.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df_channels_PB.info()), display(df_feather_PB.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the website, we will only consider the top 1000 channels (w.r.t. their subscribers) in an effort to reduce the data size, since currently, the data files are too large to be tracked on `github` (`>100MB`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of channels: 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_cc</th>\n",
       "      <th>join_date</th>\n",
       "      <th>channel</th>\n",
       "      <th>name_cc</th>\n",
       "      <th>subscribers_cc</th>\n",
       "      <th>videos_cc</th>\n",
       "      <th>subscriber_rank_sb</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2013-09-19</td>\n",
       "      <td>UCcgVECVN4OKV6DH1jLkqmcA</td>\n",
       "      <td>Jake Paul</td>\n",
       "      <td>19600000</td>\n",
       "      <td>824</td>\n",
       "      <td>144.0</td>\n",
       "      <td>2.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2011-08-10</td>\n",
       "      <td>UCpko_-a4wgz2u_DgDgd9fqA</td>\n",
       "      <td>BuzzFeedVideo</td>\n",
       "      <td>19400000</td>\n",
       "      <td>6334</td>\n",
       "      <td>158.0</td>\n",
       "      <td>2.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>UCWwWOFsW68TqXE-HZLC3WIA</td>\n",
       "      <td>The ACE Family</td>\n",
       "      <td>17600000</td>\n",
       "      <td>460</td>\n",
       "      <td>185.0</td>\n",
       "      <td>2.087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category_cc   join_date                   channel         name_cc  \\\n",
       "0  People & Blogs  2013-09-19  UCcgVECVN4OKV6DH1jLkqmcA       Jake Paul   \n",
       "1  People & Blogs  2011-08-10  UCpko_-a4wgz2u_DgDgd9fqA   BuzzFeedVideo   \n",
       "2  People & Blogs  2016-01-10  UCWwWOFsW68TqXE-HZLC3WIA  The ACE Family   \n",
       "\n",
       "   subscribers_cc  videos_cc  subscriber_rank_sb  weights  \n",
       "0        19600000        824               144.0    2.087  \n",
       "1        19400000       6334               158.0    2.087  \n",
       "2        17600000        460               185.0    2.087  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   category_cc         1000 non-null   object \n",
      " 1   join_date           1000 non-null   object \n",
      " 2   channel             1000 non-null   object \n",
      " 3   name_cc             1000 non-null   object \n",
      " 4   subscribers_cc      1000 non-null   int64  \n",
      " 5   videos_cc           1000 non-null   int64  \n",
      " 6   subscriber_rank_sb  1000 non-null   float64\n",
      " 7   weights             1000 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(4)\n",
      "memory usage: 62.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select top 1000 channels\n",
    "top_n = 1_000\n",
    "df_top_n_channels = df_channels_PB.sort_values(by='subscribers_cc', ascending=False).iloc[:top_n].copy()\n",
    "df_top_n_channels.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Number of channels: {len(df_top_n_channels)}\")\n",
    "display(df_top_n_channels.head(3))\n",
    "display(df_top_n_channels.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos: 522142\n",
      "Number of videos removed: 5031695\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "      <th>year_month</th>\n",
       "      <th>like_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>12471</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>UCzVw9odnihM5PgKSv5UnDPA</td>\n",
       "      <td>99.0</td>\n",
       "      <td>O-HFXkqbp5A</td>\n",
       "      <td>606</td>\n",
       "      <td>410.0</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>50506.0</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>0.805501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>12472</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>UCzVw9odnihM5PgKSv5UnDPA</td>\n",
       "      <td>41.0</td>\n",
       "      <td>B2F_raNXm38</td>\n",
       "      <td>629</td>\n",
       "      <td>338.0</td>\n",
       "      <td>2019-09-27</td>\n",
       "      <td>58311.0</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>0.891821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>12473</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>UCzVw9odnihM5PgKSv5UnDPA</td>\n",
       "      <td>53.0</td>\n",
       "      <td>u-qekJSjUUg</td>\n",
       "      <td>616</td>\n",
       "      <td>442.0</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>68642.0</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>0.892929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index      categories                channel_id  dislike_count  \\\n",
       "594  12471  People & Blogs  UCzVw9odnihM5PgKSv5UnDPA           99.0   \n",
       "595  12472  People & Blogs  UCzVw9odnihM5PgKSv5UnDPA           41.0   \n",
       "596  12473  People & Blogs  UCzVw9odnihM5PgKSv5UnDPA           53.0   \n",
       "\n",
       "      display_id  duration  like_count upload_date  view_count year_month  \\\n",
       "594  O-HFXkqbp5A       606       410.0  2019-10-02     50506.0    2019-10   \n",
       "595  B2F_raNXm38       629       338.0  2019-09-27     58311.0    2019-09   \n",
       "596  u-qekJSjUUg       616       442.0  2019-09-23     68642.0    2019-09   \n",
       "\n",
       "     like_rate  \n",
       "594   0.805501  \n",
       "595   0.891821  \n",
       "596   0.892929  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 522142 entries, 594 to 5543970\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   index          522142 non-null  int64         \n",
      " 1   categories     522142 non-null  object        \n",
      " 2   channel_id     522142 non-null  object        \n",
      " 3   dislike_count  516213 non-null  float64       \n",
      " 4   display_id     522142 non-null  object        \n",
      " 5   duration       522142 non-null  int64         \n",
      " 6   like_count     516213 non-null  float64       \n",
      " 7   upload_date    522142 non-null  datetime64[ns]\n",
      " 8   view_count     522142 non-null  float64       \n",
      " 9   year_month     522142 non-null  period[M]     \n",
      " 10  like_rate      514112 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(2), object(3), period[M](1)\n",
      "memory usage: 47.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select top 1000 channel helper data\n",
    "top_n_channels = df_top_n_channels[\"channel\"].tolist()\n",
    "df_top_n_helper = df_feather_PB[df_feather_PB[\"channel_id\"].isin(top_n_channels)].copy()\n",
    "\n",
    "print(f\"Number of videos: {len(df_top_n_helper)}\")\n",
    "print(f\"Number of videos removed: {len(df_feather_PB) - len(df_top_n_helper)}\")\n",
    "display(df_top_n_helper.head(3))\n",
    "display(df_top_n_helper.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the current memory usage is much lower than before, so let's save the data and use it for the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save top 1000 channels and helper DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_DATA_PATH = os.path.join(PEOPLE_AND_BLOGS_PATH, f\"top_{top_n}\")\n",
    "\n",
    "if not os.path.exists(TOP_N_DATA_PATH):\n",
    "    os.makedirs(TOP_N_DATA_PATH)\n",
    "\n",
    "df_top_n_helper.reset_index().to_feather(os.path.join(TOP_N_DATA_PATH, f\"df_top_{top_n}_helper.feather\"))\n",
    "df_top_n_channels.to_csv(os.path.join(TOP_N_DATA_PATH, f\"df_top_{top_n}_channels.csv.gz\"), compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "\n",
    "# # Assuming df_channels is your dataframe and 'name_cc' is the column with channel names\n",
    "# # Create a temporary column 'name_cc_sorted' that has punctuation removed\n",
    "# channels_PB['name_cc_sorted'] = channels_PB['name_cc'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# # Sort the dataframe using the new column\n",
    "# channels_PB.sort_values(by='name_cc_sorted', inplace=True)\n",
    "\n",
    "# # Drop the temporary sorting column\n",
    "# channels_PB.drop(columns=['name_cc_sorted'], inplace=True)\n",
    "\n",
    "# channels_PB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_PB.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_not_diverse_channels(channel_id, df_feather=df_feather_PB, show_evolution=False):\n",
    "    '''\n",
    "    Calculates the proportion of videos in the 'People & Blogs' category for a given channel.\n",
    "\n",
    "    Parameters:\n",
    "    - channel_id (str): The YouTube channel ID.\n",
    "    - df_feather (DataFrame): DataFrame containing video data.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if the proportion of 'People & Blogs' videos is less than 75%, False otherwise.\n",
    "    '''\n",
    "    df_filtered = df_feather[df_feather[\"channel_id\"] == channel_id]\n",
    "    grouped_data = df_filtered.groupby([\"year_month\", \"categories\"]).size()\n",
    "    # display(grouped_data)\n",
    "    sorted_data = grouped_data.reset_index(name='count').sort_values(['year_month', 'count'], ascending=[True, False])\n",
    "    if show_evolution:\n",
    "        display(sorted_data)\n",
    "\n",
    "    most_popular_cat = sorted_data.drop_duplicates(subset=[\"year_month\"])\n",
    "    # display(most_popular_cat)\n",
    "\n",
    "    people_and_blog_proportion = (most_popular_cat[\"categories\"] == \"People & Blogs\").mean()\n",
    "    # print(people_and_blog_proportion)\n",
    "    return people_and_blog_proportion < 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "channels_PB_transi_mask = channels_PB[:i].progress_apply(lambda channel: filter_not_diverse_channels(channel[\"channel\"]), axis=1)\n",
    "channels_PB_transi = channels_PB[:i][channels_PB_transi_mask]\n",
    "print(f\"There are {len(channels_PB[:i])} channels in PB category, but only {len(channels_PB_transi)} have less than 0.75 video in that category\")\n",
    "# channels_PB_transi.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel_id in channels_PB_transi['channel'].unique()[:5]:\n",
    "    visualize_evolution_of_channel(channel_id, df_feather_PB, channels_PB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = ['UC4-CH0epzZpD_ARhxCx6LaQ', 'UCYd0us2OtW4d4-1cfpT2ktw']\n",
    "# for channel_id in channel_ids:\n",
    "#     visualize_evolution_of_channel(channel_id, df_feather_PB, channels_PB)\n",
    "\n",
    "visualize_evolution_of_channel(channel_ids[0], df_feather_PB, channels_PB, start_date=\"2016-09\", end_date=\"2019-09\", transition_date=\"2018-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = ['UC4-CH0epzZpD_ARhxCx6LaQ', 'UC0oRdyzTbGIZUISiGQnDdiw']\n",
    "video_frequency_and_duration(channel_ids, df_feather, channels, start_date=\"2016-09\", end_date=\"2019-09\", transition_date=\"2018-03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = ['UC4-CH0epzZpD_ARhxCx6LaQ', 'UC0oRdyzTbGIZUISiGQnDdiw']\n",
    "video_likes_and_views(channel_ids, df_feather, channels, start_date=\"2016-09\", end_date=\"2019-09\", transition_date=\"2018-03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd milestone stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import os \n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def category_evolution_of_channel_v0(channel_id, channels=channels_PB, df_feather=df_feather_PB):\n",
    "#     '''\n",
    "#     Input : a channel id, channels information dataframe and video metadata via df_feather\n",
    "#     Output : annual count of number of videos of that channel in every category\n",
    "#     Note : df_feather['upload_date'] should be already in datetime format\n",
    "#     '''\n",
    "#     # get info on the channel\n",
    "#     # channel_info = channels[channels[\"channel\"] == channel_id]\n",
    "#     # display(channel_info)\n",
    "\n",
    "#     df_feather_filt = df_feather[df_feather[\"channel_id\"] == channel_id]\n",
    "#     # For every year, count videos in each category\n",
    "#     grouped_data = df_feather_filt[[\"year_month\", \"categories\", \"channel_id\"]]\n",
    "#     grouped_data = grouped_data.groupby([\"year_month\", \"categories\"]).count()\n",
    "#     # Sort the values (need to transform in a regular dataframe and then put back indexes)\n",
    "#     sorted_data = grouped_data.reset_index().sort_values(['year_month', 'channel_id'], ascending=[True, False])\n",
    "#     sorted_data.set_index(['year_month', 'categories'], inplace=True)\n",
    "#     # display(sorted_data)\n",
    "\n",
    "#     # Select only the most popular category every year\n",
    "#     most_popular_cat = sorted_data.reset_index().drop_duplicates(subset=[\"year_month\"])\n",
    "#     # display(most_popular_cat)\n",
    "\n",
    "#     people_and_blog_proportion = len(most_popular_cat[most_popular_cat[\"categories\"]==\"People & Blogs\"]) / len(most_popular_cat)\n",
    "#     # print(people_and_blog_proportion)\n",
    "\n",
    "#     return people_and_blog_proportion < 0.75\n",
    "\n",
    "# # channel_id = 'UCcgVECVN4OKV6DH1jLkqmcA'\n",
    "# # category_evolution_of_channel(channel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK_PATH = os.getcwd()\n",
    "# DIR_PATH = os.path.dirname(NOTEBOOK_PATH)\n",
    "# DATA_PATH = os.path.join(DIR_PATH, \"data_youniverse\")\n",
    "# UTILS_PATH = os.path.join(DIR_PATH, \"utils\")\n",
    "# CATEGORY = \"Science & Technology\"\n",
    "\n",
    "# # append utils path and import utils\n",
    "# sys.path.append(UTILS_PATH)\n",
    "# from ploting import *\n",
    "# from loading import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_channels_en = pd.read_csv(f\"{DATA_PATH}/df_channels_en.tsv.gz\", compression=\"infer\", sep=\"\\t\") \n",
    "# # df_channels_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_timeseries_en = pd.read_csv(f\"{DATA_PATH}/df_timeseries_en.tsv.gz\", compression=\"infer\", sep=\"\\t\") # 20s\n",
    "# # df_timeseries_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_timeseries_en[df_timeseries_en['category'].isna()].channel.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_channels_filt = df_channels_en[df_channels_en['category_cc'] == CATEGORY].copy()\n",
    "# df_timeseries_filt = df_timeseries_en[df_timeseries_en['category'] == CATEGORY].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper_filt = read_and_filter_feather(f\"{DATA_PATH}/yt_metadata_helper.feather\", CATEGORY)\n",
    "# helper_filt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UNCOMMENT IF NEEDED\n",
    "# yt_metadata_filtered = load_and_filter_jsonl_gz_file_by_chunks(f\"{DATA_PATH}/yt_metadata_en.jsonl.gz\", CATEGORY) # 21m for pets and animals (should be the same for the other at it is reading all the file anyway)\n",
    "# yt_metadata_filtered.to_csv(f\"{DATA_PATH}/yt_metadata_pets&animals.csv.gz\", index=False, compression=\"gzip\") # stock the results\n",
    "# yt_metadata_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yt_metadata_filtered.iloc[-1]['tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of pets & animals category and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yt_metadata_filt = pd.read_csv(f\"{DATA_PATH}/yt_metadata_pets&animals.csv.gz\", compression=\"infer\")\n",
    "# # les channels id sont les vrai, ont peut retrouver les chaines youtube !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yt_metadata_filt['upload_date'] = pd.to_datetime(yt_metadata_filt['upload_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yt_metadata_filt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the top 3 tags for a range of years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years = range(2016, 2020)  # or whatever years are applicable\n",
    "# for year in years:\n",
    "#     yt_metadata_filt_year = yt_metadata_filt[yt_metadata_filt['upload_date'].dt.year == year]\n",
    "#     if not yt_metadata_filt_year.empty:\n",
    "#         try:\n",
    "#             # Assuming the function plot_topN_tag is correctly defined and can handle cases with less than N tags\n",
    "#             plot_topN_tag(yt_metadata_filt_year['tags'], 3)\n",
    "#         except Exception as e:\n",
    "#             print(f\"An error occurred for year {year}: {e}\")\n",
    "#     else:\n",
    "#         print(f\"No data available for year {year}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of NaN values (not extensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_dataframe(df):\n",
    "#     # Remove rows where 'tags' is empty or NaN\n",
    "#     initial_row_count = len(df)\n",
    "#     df = df.dropna(subset=['tags'])  # Drops rows with NaN in 'tags'\n",
    "#     df = df[df['tags'].str.strip().astype(bool)]  # Drops rows with empty 'tags'\n",
    "#     cleaned_row_count = len(df)\n",
    "\n",
    "#     # Check for NaN values in 'like_count'\n",
    "#     like_count_nan = df['like_count'].isna().sum()\n",
    "#     if like_count_nan > 0:\n",
    "#         # Handle NaN values here. Options: fill with 0, mean, median, etc.\n",
    "#         # Example: df['like_count'].fillna(df['like_count'].median(), inplace=True)\n",
    "#         # For now, we'll just drop these rows\n",
    "#         df = df.dropna(subset=['like_count'])\n",
    "\n",
    "#     # Print out the cleaning summary\n",
    "#     print(f\"Rows with empty 'tags' removed: {initial_row_count - cleaned_row_count}\")\n",
    "#     print(f\"Rows with NaN in 'like_count': {like_count_nan}\")\n",
    "\n",
    "#     return df\n",
    "\n",
    "# # Clean the yt_metadata_filtered dataframe\n",
    "# yt_metadata_filt_clean = clean_dataframe(yt_metadata_filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot evolution of most popular tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_top_tags_for_year(df, year, top_n=5):\n",
    "#     \"\"\" Get the top N tags for a given year from the dataframe \"\"\"\n",
    "#     year_data = df[df['upload_date'].dt.year == year]\n",
    "#     tag_list = year_data['tags'].str.split(',').explode()\n",
    "#     top_tags = tag_list.value_counts().head(top_n).index\n",
    "#     return top_tags\n",
    "\n",
    "# def count_tag_appearances_by_year(df, tags):\n",
    "#     \"\"\" Count the number of appearances of each tag by year \"\"\"\n",
    "#     df['year'] = df['upload_date'].dt.year\n",
    "#     tag_counts_by_year = {tag: df[df['tags'].str.contains(tag)]['year'].value_counts().sort_index() for tag in tags}\n",
    "#     return tag_counts_by_year\n",
    "\n",
    "# def plot_tag_counts(tag_counts_by_year):\n",
    "#     \"\"\" Plot the evolution of tag counts over the years \"\"\"\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     for tag, counts in tag_counts_by_year.items():\n",
    "#         plt.plot(counts.index, counts.values, label=tag)\n",
    "    \n",
    "#     plt.xlabel('Year')\n",
    "#     plt.ylabel('Number of Appearances')\n",
    "#     plt.title('Evolution of Tag Appearances by Year')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# top_tags_2019 = get_top_tags_for_year(yt_metadata_filt_clean, 2019)\n",
    "# tag_counts_by_year = count_tag_appearances_by_year(yt_metadata_filt_clean, top_tags_2019)\n",
    "# plot_tag_counts(tag_counts_by_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe of statistics grouped by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert `upload_date` to DateTime and extract the year.\n",
    "# yt_metadata_filt['upload_year'] = pd.to_datetime(yt_metadata_filt['upload_date']).dt.year\n",
    "\n",
    "# # Group by the extracted year.\n",
    "# grouped = yt_metadata_filt.groupby('upload_year')\n",
    "\n",
    "# # Initialize a dictionary to hold aggregated data.\n",
    "# aggregated_data = {}\n",
    "\n",
    "# # Iterate over each group to perform aggregations.\n",
    "# for name, group in grouped:\n",
    "#     # Get the most popular tag for each year.\n",
    "#     popular_tag = group['tags'].str.split(',').explode().value_counts().idxmax()\n",
    "    \n",
    "#     # Get other statistics for each year.\n",
    "#     aggregated_data[name] = {\n",
    "#         'most_popular_tag': popular_tag,\n",
    "#         'total_like_count': group['like_count'].sum(),\n",
    "#         'total_videos': group['upload_date'].count(),\n",
    "#         'total_duration': group['duration'].sum(),\n",
    "#         'unique_channels': group['channel_id'].nunique(),\n",
    "#         'total_dislike_count': group['dislike_count'].sum(),\n",
    "#         'total_view_count': group['view_count'].sum(),\n",
    "#         'mean_dislike_count': group['dislike_count'].mean(),\n",
    "#         'mean_like_count': group['like_count'].mean(),\n",
    "#         'mean_duration': group['duration'].mean(),\n",
    "#     }\n",
    "\n",
    "# # Convert aggregated data to a DataFrame.\n",
    "# stats_df = pd.DataFrame.from_dict(aggregated_data, orient='index')\n",
    "\n",
    "# # Display the DataFrame\n",
    "# stats_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot evolution of metrics of previous dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_stats_over_years(df, columns):\n",
    "#     \"\"\"\n",
    "#     Plots the evolution of specified columns from a DataFrame over the years.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - df: pandas DataFrame with a year index and columns to plot.\n",
    "#     - columns: list of strings representing the column names to plot.\n",
    "#     \"\"\"\n",
    "#     if not isinstance(columns, list):\n",
    "#         columns = [columns]  # Convert to list if a single column name is passed.\n",
    "        \n",
    "#     for column in columns:\n",
    "#         if column in df.columns:\n",
    "#             plt.plot(df.index, df[column], label=column)\n",
    "#         else:\n",
    "#             print(f\"Column '{column}' not found in the DataFrame.\")\n",
    "    \n",
    "#     plt.xlabel('Year')\n",
    "#     plt.ylabel('Value')\n",
    "#     plt.title('Evolution of Statistics Over Years')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_stats_over_years(stats_df, ['total_like_count', 'total_dislike_count'])\n",
    "# plot_stats_over_years(stats_df, ['mean_dislike_count', 'mean_like_count', 'mean_duration'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
